import torch
import torch.nn as nn
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import argparse
import os

from configs.train_arguements import get_arguments
from src.data.get_dataset import get_dataset
from src.models.get_model import get_model

# ì „ì—­ ë¦¬ìŠ¤íŠ¸ì— LayerNorm ì…ì¶œë ¥ ì €ì¥
ln_inputs_outputs = []

# 1. LayerNorm Hook ë“±ë¡ í•¨ìˆ˜
def register_ln_hooks(model):
    hooks = []

    def get_hook(name):
        def hook(module, input, output):
            input_tensor = input[0].detach().cpu().flatten().numpy()
            output_tensor = output.detach().cpu().flatten().numpy()
            ln_inputs_outputs.append((name, input_tensor, output_tensor))
        return hook

    for name, module in model.named_modules():
        if isinstance(module, nn.LayerNorm):
            hooks.append(module.register_forward_hook(get_hook(name)))

    if not hooks:
        print("âš ï¸ No LayerNorm modules found.")
    return hooks

# 2. ì‹œê°í™” í•¨ìˆ˜ - ëª¨ë“  LayerNorm ë ˆì´ì–´ í¬í•¨
def plot_ln_io(ln_inputs_outputs, max_layers=None):
    if not ln_inputs_outputs:
        print("âš ï¸ No LayerNorm data found!")
        return
    
    print(f"ğŸ“Š Found {len(ln_inputs_outputs)} LayerNorm layers:")
    for name, _, _ in ln_inputs_outputs:
        print(f"  - {name}")
    
    # max_layersê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ëª¨ë“  ë ˆì´ì–´ ì‹œê°í™”
    n = len(ln_inputs_outputs) if max_layers is None else min(len(ln_inputs_outputs), max_layers)
    
    # ê·¸ë¦¬ë“œ ë ˆì´ì•„ì›ƒ ê³„ì‚°
    cols = min(4, n)
    rows = (n + cols - 1) // cols if cols > 0 else 1

    plt.figure(figsize=(cols * 4, rows * 3))
    
    for i in range(n):
        name, x, y = ln_inputs_outputs[i]
        
        # ë°ì´í„° ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ì€ ì ì€ ì„±ëŠ¥ ì €í•˜)
        max_points = 10000000
        if len(x) > max_points:
            indices = np.random.choice(len(x), max_points, replace=False)
            x_sampled = x[indices]
            y_sampled = y[indices]
        else:
            x_sampled = x
            y_sampled = y
        
        plt.subplot(rows, cols, i + 1)
        
        # ì‚°ì ë„ ê·¸ë¦¬ê¸°
        plt.scatter(x_sampled, y_sampled, s=0.2, alpha=0.5, color='blue')
        
        # ì¶”ì„¸ì„  ì¶”ê°€ (binning ë°©ì‹)
        if len(x_sampled) > 100:
            n_bins = 50
            x_min, x_max = x_sampled.min(), x_sampled.max()
            x_bins = np.linspace(x_min, x_max, n_bins)
            
            y_means = []
            x_centers = []
            
            for j in range(len(x_bins) - 1):
                mask = (x_sampled >= x_bins[j]) & (x_sampled < x_bins[j+1])
                if np.sum(mask) > 5:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ
                    y_means.append(np.mean(y_sampled[mask]))
                    x_centers.append((x_bins[j] + x_bins[j+1]) / 2)
            
            if len(x_centers) > 3:
                plt.plot(x_centers, y_means, 'red', linewidth=2, alpha=0.8)
        
        # ë™ì  ì¶• ë²”ìœ„ ì„¤ì • (ì‹¤ì œ ë°ì´í„°ì˜ ìµœì†Œ~ìµœëŒ€ê°’)
        x_min, x_max = x_sampled.min(), x_sampled.max()
        y_min, y_max = y_sampled.min(), y_sampled.max()
        
        # ì•½ê°„ì˜ ì—¬ë°± ì¶”ê°€ (5%)
        x_margin = (x_max - x_min) * 0.05 if x_max != x_min else 0.1
        y_margin = (y_max - y_min) * 0.05 if y_max != y_min else 0.1
        
        plt.xlim(x_min - x_margin, x_max + x_margin)
        plt.ylim(y_min - y_margin, y_max + y_margin)
        
        # ì¶• í‹±ì„ ë°ì´í„° ë²”ìœ„ì— ë§ê²Œ ì„¤ì •
        if x_max != x_min:
            x_ticks = np.linspace(x_min, x_max, 5)
            plt.xticks(x_ticks, [f'{tick:.1f}' for tick in x_ticks])
        
        if y_max != y_min:
            y_ticks = np.linspace(y_min, y_max, 5)
            plt.yticks(y_ticks, [f'{tick:.1f}' for tick in y_ticks])
        
        # ë ˆì´ì–´ ì´ë¦„ì„ ë” ê°„ê²°í•˜ê²Œ í‘œì‹œ
        display_name = name.split('.')[-2:] if '.' in name else name
        display_name = '.'.join(display_name) if isinstance(display_name, list) else display_name
        
        plt.title(display_name, fontsize=8)
        plt.xlabel("LN input", fontsize=8)
        plt.ylabel("LN output", fontsize=8)
        plt.grid(True, alpha=0.3)
        
        # ë°ì´í„° ë²”ìœ„ ì •ë³´ ì¶œë ¥
        print(f"Layer {name}:")
        print(f"  Input range: [{x_min:.2f}, {x_max:.2f}]")
        print(f"  Output range: [{y_min:.2f}, {y_max:.2f}]")
        print(f"  Data points: {len(x_sampled)}")
    
    plt.suptitle(f"All LayerNorm Layers - Input vs Output\n({n} layers visualized)", fontsize=16)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.savefig("all_layernorm_plot.png", dpi=300, bbox_inches='tight')
    print(f"âœ… Plot saved as all_layernorm_plot.png")
    plt.show()

# 3. ë ˆì´ì–´ë³„ ì„¸ë¶€ ë¶„ì„ í•¨ìˆ˜ ì¶”ê°€
def analyze_ln_statistics(ln_inputs_outputs):
    """ê° LayerNorm ë ˆì´ì–´ì˜ í†µê³„ ë¶„ì„"""
    print("\nğŸ“ˆ LayerNorm Layer Statistics:")
    print("=" * 80)
    
    for i, (name, x, y) in enumerate(ln_inputs_outputs):
        print(f"\n[{i+1:2d}] {name}")
        print(f"     Input  - Mean: {np.mean(x):7.3f}, Std: {np.std(x):7.3f}, Range: [{np.min(x):7.3f}, {np.max(x):7.3f}]")
        print(f"     Output - Mean: {np.mean(y):7.3f}, Std: {np.std(y):7.3f}, Range: [{np.min(y):7.3f}, {np.max(y):7.3f}]")
        
        # ì •ê·œí™” íš¨ê³¼ ì¸¡ì •
        input_var = np.var(x)
        output_var = np.var(y)
        var_reduction = (input_var - output_var) / input_var * 100 if input_var > 0 else 0
        print(f"     Variance reduction: {var_reduction:5.1f}%")

# 4. ê°€ì¤‘ì¹˜ ë¡œë“œ í•¨ìˆ˜
def load_pretrained_weights(model, checkpoint_path):
    """
    ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë¸ì— ë¡œë“œí•©ë‹ˆë‹¤.
    """
    if not os.path.exists(checkpoint_path):
        print(f"âŒ Checkpoint file not found: {checkpoint_path}")
        return model
    
    try:
        print(f"ğŸ“‚ Loading checkpoint from: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # checkpoint êµ¬ì¡° í™•ì¸
        if isinstance(checkpoint, dict):
            if 'model' in checkpoint:
                state_dict = checkpoint['model']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            elif 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint
        
        # ëª¨ë¸ì— ê°€ì¤‘ì¹˜ ë¡œë“œ
        model.load_state_dict(state_dict, strict=False)
        print("âœ… Pretrained weights loaded successfully!")
        
        # ë¡œë“œëœ ì •ë³´ ì¶œë ¥
        if isinstance(checkpoint, dict):
            if 'epoch' in checkpoint:
                print(f"ğŸ“Š Epoch: {checkpoint['epoch']}")
            if 'best_miou' in checkpoint:
                print(f"ğŸ“Š Best mIoU: {checkpoint['best_miou']:.4f}")
                
    except Exception as e:
        print(f"âŒ Error loading checkpoint: {e}")
        print("Continuing with randomly initialized weights...")
    
    return model

# 5. í†µí•© ì‹¤í–‰ í•¨ìˆ˜
def profile_ln_behavior_in_transformer(args):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ Using device: {device}")

    # ì´ë¯¸ì§€ 1ê°œ ìƒ˜í”Œ ë¶ˆëŸ¬ì˜¤ê¸°
    train_dataset, _ = get_dataset(args)
    sample = train_dataset[0]
    image = sample['pixel_values'] if isinstance(sample, dict) else sample

    # Transform ì ìš©
    if not isinstance(image, torch.Tensor):
        transform = transforms.Compose([
            transforms.Resize((args.input_size, args.input_size)),
            transforms.ToTensor(),
        ])
        image = transform(image)

    input_tensor = image.unsqueeze(0).to(device) if image.dim() == 3 else image.to(device)
    print(f"ğŸ“¥ Input tensor shape: {input_tensor.shape}")

    # ëª¨ë¸ ë¡œë”©
    model = get_model(args).to(device)
    
    # ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    checkpoint_path = "/home/urp_jwl/.vscode-server/data/EffiSeg-lucinaaal/ckpt/segformerb2_teacher_cityscapes.pth"
    model = load_pretrained_weights(model, checkpoint_path)
    
    model.eval()
    
    # Hook ë“±ë¡
    hooks = register_ln_hooks(model)
    print(f"ğŸ”— Registered {len(hooks)} LayerNorm hooks")

    # Forward pass (hook ì‘ë™)
    print("ğŸ”„ Running forward pass...")
    with torch.no_grad():
        output = model(input_tensor)
        print(f"ğŸ“¤ Output shape: {output.shape if hasattr(output, 'shape') else type(output)}")

    # Hook ì œê±°
    for h in hooks:
        h.remove()

    print(f"ğŸ“Š Collected {len(ln_inputs_outputs)} LayerNorm input-output pairs")
    
    # í†µê³„ ë¶„ì„
    if ln_inputs_outputs:
        analyze_ln_statistics(ln_inputs_outputs)
        
        # ì‹œê°í™” (ëª¨ë“  ë ˆì´ì–´)
        plot_ln_io(ln_inputs_outputs)
    else:
        print("âš ï¸ No LayerNorm data collected for visualization")

# 6. ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
def parse_args():
    parser = argparse.ArgumentParser(description='LayerNorm Analysis with Pretrained Weights')
    parser.add_argument('--model', type=str, default='SegformerB2', 
                       help='Model name (default: SegformerB2)')
    parser.add_argument('--checkpoint', type=str, 
                       default='/home/urp_jwl/.vscode-server/data/EffiSeg-lucinaaal/ckpt/segformerb2_teacher_cityscapes.pth',
                       help='Path to checkpoint file')
    parser.add_argument('--max_layers', type=int, default=None,
                       help='Maximum number of layers to visualize (default: all)')
    
    return parser.parse_args()

# 7. ì‹¤í–‰
if __name__ == '__main__':
    # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    cmd_args = parse_args()
    
    # ê¸°ë³¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    args = get_arguments()
    
    # ëª…ë ¹í–‰ ì¸ìë¡œ ëª¨ë¸ ì´ë¦„ ì˜¤ë²„ë¼ì´ë“œ
    if hasattr(args, 'model'):
        args.model = cmd_args.model
    elif hasattr(args, 'model_name'):
        args.model_name = cmd_args.model
    else:
        # argsì— model ì†ì„±ì´ ì—†ìœ¼ë©´ ì¶”ê°€
        setattr(args, 'model', cmd_args.model)
    
    print(f"ğŸš€ Starting LayerNorm analysis with model: {cmd_args.model}")
    print(f"ğŸ“ Checkpoint path: {cmd_args.checkpoint}")
    if cmd_args.max_layers:
        print(f"ğŸ”¢ Max layers to visualize: {cmd_args.max_layers}")
    else:
        print("ğŸ”¢ Visualizing all LayerNorm layers")
    
    # ì „ì—­ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™” (ì¬ì‹¤í–‰ ì‹œë¥¼ ìœ„í•´)
    ln_inputs_outputs.clear()
    
    profile_ln_behavior_in_transformer(args)